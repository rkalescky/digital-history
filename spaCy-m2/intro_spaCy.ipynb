{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP with spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook is divided into three sections: \n",
    "\n",
    "__Section 1__ will introduce spaCy\n",
    "\n",
    "__Section 2__ will use spaCy on Hansard debates tagged with the speaker \"Gladstone.\" Like [Klein's Notebook](https://github.com/laurenfklein/emory-qtm340/blob/master/notebooks/class11-nlp-spacy-complete.ipynb) we will: 1) extract words; 2) extract parts-of-speech; and 3) extract syntactic units.\n",
    "\n",
    "__Section 3__ contains your assignment. You will be asked to reiterate the same steps on Bob Dole's speeches from the Stanford Congressional Records. Section 3 will walk you through the process of aggregating and parsing the data, but it will be up to you to extract words, parts-of-speech, and syntactic units. After extracting words, parts-of-speech, and syntactic units you will be tasked with generating a few visualizations that tells us about the language usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: What is spaCy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy is a comprehensive, industrial-grade software library for natural language processing (NLP). It provides tools to extract language patterns. From a linguistic standpoint, spaCy outperforms popular tools like NLTK because spaCy offers advanced statistical language models from which it parses and tags words.\n",
    "\n",
    "spaCy's NLP pipeline is shown below. Provided with text, spaCy can tokenize, tag, parse, perform named entity recognition, and more.\n",
    "\n",
    "The pipeline returns a parsed Doc object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data:image/png;base64,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\n",
    "\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy's linguistic features include:\n",
    "\n",
    "1. Syntactic dependency parsing </br>\n",
    "Syntax is the ordering from which words derive meaning within a sentence. After parsing words' syntactic dependencies, analysts can reconstruct grammatical rules for the purpose of extracting parts-of-speech.\n",
    "\n",
    "2. Part-of-speech tagging </br>\n",
    "Parts-of-speech are lexical categories that corresponds with a word's syntactic function--categories like \"adjective\" or \"verb.\" spaCy tags parts-of-speech using a statistical model to predict which tag should most likely appear in a given context.\n",
    "\n",
    "3. Rule-based morphology </br>\n",
    "Morphology refers to word form and how different forms relate to other words in a sentence. Consider the verbs \"write\" and \"writing\" in the following sentences:</br>\n",
    " `\"I write programs.\"` </br>\n",
    " `\"I am writing a program.\"`</br>\n",
    "The verb in the first sentence is in its base form. The verb in the second sentence is in its inflectional form. It is important to note that inflectional forms do not change a word's part-of-speech. Morphology is important to the process of lemmatization, or transforming words to their base form. Lemmatizing words before measuring them can streamline our results so words like \"rent\" and \"rented\" are not counted separately.\n",
    "\n",
    "4. Tokenization </br>\n",
    "Tokenization is the process of splitting texts into meaningful segments like n-grams. spaCy has tokenization support for over 59 languages.\n",
    "\n",
    "5. Entity Extraction </br>\n",
    "spaCy offers entity recognition for a variety of named and numeric entities including locations, person names, and organizations. Users can also add their own classes of entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Extracting Parts-of-Speech from Hansard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First import the required modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, spacy, warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then load the language model you will use to parse the data. \n",
    "\n",
    "> Note: Klein uses the language model `'en'` (for English) whereas our Python environment uses `'en_core_web_sm'` (for a somewhat smaller language model). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the data, debates tagged with the speaker \"Gladstone.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gladstone = pd.read_csv('/scratch/group/history/hist_3368-jguldi/gladstone_speeches.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_id</th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "      <th>speechdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S3V0015P0_14408</td>\n",
       "      <td>Mr. Gladstone</td>\n",
       "      <td>said, the Reform Bill had not produced at Live...</td>\n",
       "      <td>1833-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S3V0015P0_14409</td>\n",
       "      <td>Mr. Gladstone</td>\n",
       "      <td>He would venture to say, however, that no corr...</td>\n",
       "      <td>1833-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S3V0015P0_14414</td>\n",
       "      <td>Mr. Gladstone</td>\n",
       "      <td>said, that no such practices had taken place, ...</td>\n",
       "      <td>1833-02-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S3V0016P0_6834</td>\n",
       "      <td>Mr. Gladstone</td>\n",
       "      <td>stated, that from a letter he had received, he...</td>\n",
       "      <td>1833-03-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S3V0026P0_7706</td>\n",
       "      <td>Mr. Gladstone</td>\n",
       "      <td>was unable to say that such persons had not be...</td>\n",
       "      <td>1835-02-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10134</th>\n",
       "      <td>S3V0082P0_9537</td>\n",
       "      <td>Mr. Gladstone</td>\n",
       "      <td>Upon the whole, here was a mass of circumstant...</td>\n",
       "      <td>1845-07-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10135</th>\n",
       "      <td>S3V0082P0_9538</td>\n",
       "      <td>Mr. Gladstone</td>\n",
       "      <td>The obligation of these Treaties—and he wished...</td>\n",
       "      <td>1845-07-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10136</th>\n",
       "      <td>S3V0082P0_9539</td>\n",
       "      <td>Mr. Gladstone</td>\n",
       "      <td>And, lastly, notwithstanding the disadvantage ...</td>\n",
       "      <td>1845-07-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10137</th>\n",
       "      <td>S3V0082P0_9540</td>\n",
       "      <td>Mr. Gladstone</td>\n",
       "      <td>He had not knowingly passed by any fact bearin...</td>\n",
       "      <td>1845-07-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10138</th>\n",
       "      <td>S3V0082P0_9560</td>\n",
       "      <td>Mr. Gladstone</td>\n",
       "      <td>I did not say that that demand was made under ...</td>\n",
       "      <td>1845-07-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10139 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sentence_id        speaker  \\\n",
       "0      S3V0015P0_14408  Mr. Gladstone   \n",
       "1      S3V0015P0_14409  Mr. Gladstone   \n",
       "2      S3V0015P0_14414  Mr. Gladstone   \n",
       "3       S3V0016P0_6834  Mr. Gladstone   \n",
       "4       S3V0026P0_7706  Mr. Gladstone   \n",
       "...                ...            ...   \n",
       "10134   S3V0082P0_9537  Mr. Gladstone   \n",
       "10135   S3V0082P0_9538  Mr. Gladstone   \n",
       "10136   S3V0082P0_9539  Mr. Gladstone   \n",
       "10137   S3V0082P0_9540  Mr. Gladstone   \n",
       "10138   S3V0082P0_9560  Mr. Gladstone   \n",
       "\n",
       "                                                    text  speechdate  \n",
       "0      said, the Reform Bill had not produced at Live...  1833-02-21  \n",
       "1      He would venture to say, however, that no corr...  1833-02-21  \n",
       "2      said, that no such practices had taken place, ...  1833-02-21  \n",
       "3      stated, that from a letter he had received, he...  1833-03-06  \n",
       "4      was unable to say that such persons had not be...  1835-02-27  \n",
       "...                                                  ...         ...  \n",
       "10134  Upon the whole, here was a mass of circumstant...  1845-07-15  \n",
       "10135  The obligation of these Treaties—and he wished...  1845-07-15  \n",
       "10136  And, lastly, notwithstanding the disadvantage ...  1845-07-15  \n",
       "10137  He had not knowingly passed by any fact bearin...  1845-07-15  \n",
       "10138  I did not say that that demand was made under ...  1845-07-15  \n",
       "\n",
       "[10139 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gladstone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gladstone` is a DataFrame with four columns and 10139 rows. We could parse the data in this form, however, parsing time is relative to the size of the data we are weilding. Reducing the data to just the components we need will accelerate our work. The following code makes a copy of just the `text` column from `gladstone`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gladstone_small = gladstone['text'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        said, the Reform Bill had not produced at Live...\n",
       "1        He would venture to say, however, that no corr...\n",
       "2        said, that no such practices had taken place, ...\n",
       "3        stated, that from a letter he had received, he...\n",
       "4        was unable to say that such persons had not be...\n",
       "                               ...                        \n",
       "10134    Upon the whole, here was a mass of circumstant...\n",
       "10135    The obligation of these Treaties—and he wished...\n",
       "10136    And, lastly, notwithstanding the disadvantage ...\n",
       "10137    He had not knowingly passed by any fact bearin...\n",
       "10138    I did not say that that demand was made under ...\n",
       "Name: text, Length: 10139, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gladstone_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gladstone_small` doesn't look like a pandas DataFrame. Invoking `type()` on `gladstone_small` shows that it is a pandas series. The number on the left is the sentence's index, and the text on the right is the debate text. A series is generally lighter weight than a DataFrame of the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(gladstone_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a smaller data set, let's parse the text with spaCy. \n",
    "\n",
    "> Note: Klein just uses `nlp()` because she is parsing a single element, or a single unit of data. We need to iterate through multiple rows with multiple elements, which can be done using `nlp.pipe()` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.3 s, sys: 4.87 s, total: 35.2 s\n",
      "Wall time: 35.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gladstone_doc = list(nlp.pipe(gladstone_small, disable = [\"ent\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the ouput, `gladstone_doc`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[said, the Reform Bill had not produced at Liverpool the effect which had been anticipated from it.,\n",
       " He would venture to say, however, that no corrupt influence had been used either by the noble Lord or by any of his supporters during his last election.,\n",
       " said, that no such practices had taken place, to the best of his belief.,\n",
       " stated, that from a letter he had received, he believed the petition to be signed by many respectable individuals, and that it should have his support.,\n",
       " was unable to say that such persons had not been appointed as special Magistrates in any case.,\n",
       " Thus much, however, he could say, that no person interested in the West-India Colonies had been appointed as a special Magistrate in the Island of Jamaica.,\n",
       " It was impossible to give any absolute pledge upon the subject, because the Governor of the Colony retained, under the Act, the power of doing anything which was necessary, in his judgment, for the preservation of its peace and tranquillity.,\n",
       " It was important that the hon.,\n",
       " Gentleman and the House should be aware that the Governor of Jamaica had refused his assent to an Act making the appointment of these Magistrates absolutely necessary and a matter of course, and that his conduct met with the fullest approbation of the Government and of the Colony.,\n",
       " Nothing was further from the wish of the English Government—nothing was further from the wish of the Colonial Government—nothing could be more improper than that that appointment should be deemed a matter of necessity in every case.]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gladstone_doc[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our data no longer looks like a panda's series. Instead, as indicated by the brackets, every sentence looks like it belongs to a list. Less obvious, however, is that every word is now a generator object, in this case, a spaCy token object.\n",
    "\n",
    "Let's see if this assessment is true by invoking `type()` on `gladstone_doc` and then on every word in `gladstone_doc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(gladstone_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word for word in gladstone_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though these generator objects look like regular character strings, they're not. They're spaCy token objects.\n",
    "\n",
    "Therefore, unlike a string, every word has associated attributes like __.text__, __.lemma___, __.pos___ (and more) where __.text__ stands for the word as it appears in the data set, __.lemma__ refers to the lemmatized version of the word, and __.pos___ stands for part-of-speech. \n",
    "\n",
    "> For a full list of token object attributes and their descriptions, see the list of token attributes in [spaCy's documentation](https://spacy.io/usage/rule-based-matching#adding-patterns-attributes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view a token's attributes we can created a nested for loop that iterates through every list in `gladstone_doc` and every word in every list. The following code extracts the word as it appears in the data set and also shows its lemmatized form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_and_lemma = []\n",
    "\n",
    "for ls in gladstone_doc:\n",
    "    for word in ls:\n",
    "        row = (word.text, word.lemma_)\n",
    "        token_and_lemma.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 'say'),\n",
       " (',', ','),\n",
       " ('the', 'the'),\n",
       " ('Reform', 'Reform'),\n",
       " ('Bill', 'Bill'),\n",
       " ('had', 'have'),\n",
       " ('not', 'not'),\n",
       " ('produced', 'produce'),\n",
       " ('at', 'at'),\n",
       " ('Liverpool', 'Liverpool'),\n",
       " ('the', 'the'),\n",
       " ('effect', 'effect'),\n",
       " ('which', 'which'),\n",
       " ('had', 'have'),\n",
       " ('been', 'be'),\n",
       " ('anticipated', 'anticipate'),\n",
       " ('from', 'from'),\n",
       " ('it', '-PRON-'),\n",
       " ('.', '.'),\n",
       " ('He', '-PRON-'),\n",
       " ('would', 'would'),\n",
       " ('venture', 'venture'),\n",
       " ('to', 'to'),\n",
       " ('say', 'say'),\n",
       " (',', ','),\n",
       " ('however', 'however'),\n",
       " (',', ','),\n",
       " ('that', 'that'),\n",
       " ('no', 'no'),\n",
       " ('corrupt', 'corrupt')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_and_lemma[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the words in `token_and_lemma` are similar, but let's look at some important distinctions. __anticipated__ is lemmatized to __anticipate__. __been__ is lemmatized to __be__. Lemmatizing words is important if we don't want to count __anticipated__ and __anticipate__ as different words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parts-of-Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also view each word's part-of-speech:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_and_pos = []\n",
    "\n",
    "for ls in gladstone_doc:\n",
    "    for word in ls:\n",
    "        row = (word.text, word.pos_)\n",
    "        token_and_pos.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 'VERB'),\n",
       " (',', 'PUNCT'),\n",
       " ('the', 'DET'),\n",
       " ('Reform', 'PROPN'),\n",
       " ('Bill', 'PROPN'),\n",
       " ('had', 'AUX'),\n",
       " ('not', 'PART'),\n",
       " ('produced', 'VERB'),\n",
       " ('at', 'ADP'),\n",
       " ('Liverpool', 'PROPN'),\n",
       " ('the', 'DET'),\n",
       " ('effect', 'NOUN'),\n",
       " ('which', 'DET'),\n",
       " ('had', 'AUX'),\n",
       " ('been', 'AUX'),\n",
       " ('anticipated', 'VERB'),\n",
       " ('from', 'ADP'),\n",
       " ('it', 'PRON'),\n",
       " ('.', 'PUNCT'),\n",
       " ('He', 'PRON'),\n",
       " ('would', 'VERB'),\n",
       " ('venture', 'VERB'),\n",
       " ('to', 'PART'),\n",
       " ('say', 'VERB'),\n",
       " (',', 'PUNCT'),\n",
       " ('however', 'ADV'),\n",
       " (',', 'PUNCT'),\n",
       " ('that', 'SCONJ'),\n",
       " ('no', 'DET'),\n",
       " ('corrupt', 'ADJ')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_and_pos[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or extract a single type of part-of-speech. The following code iterates through every list in `gladstone_doc` and every word in every list. If the lemmatized word's part-of-speech is a noun it is appended to our empty list, `nouns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.symbols import NOUN\n",
    "\n",
    "nouns = []\n",
    "\n",
    "for ls in gladstone_doc:\n",
    "    for word in ls:\n",
    "        if word.pos_ == 'NOUN':\n",
    "            nouns.append(word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['effect',\n",
       " 'influence',\n",
       " 'supporter',\n",
       " 'election',\n",
       " 'practice',\n",
       " 'place',\n",
       " 'belief',\n",
       " 'letter',\n",
       " 'petition',\n",
       " 'individual',\n",
       " 'support',\n",
       " 'person',\n",
       " 'case',\n",
       " 'person',\n",
       " 'magistrate',\n",
       " 'pledge',\n",
       " 'subject',\n",
       " 'power',\n",
       " 'judgment',\n",
       " 'preservation',\n",
       " 'peace',\n",
       " 'tranquillity',\n",
       " 'assent',\n",
       " 'appointment',\n",
       " 'matter',\n",
       " 'course',\n",
       " 'conduct',\n",
       " 'approbation',\n",
       " 'wish',\n",
       " 'wish']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code performs the same operation for adjectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.symbols import ADJ\n",
    "\n",
    "adjectives = []\n",
    "\n",
    "for ls in gladstone_doc:\n",
    "    for word in ls:\n",
    "        if word.pos_ == 'ADJ':\n",
    "            adjectives.append(word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['corrupt',\n",
       " 'noble',\n",
       " 'last',\n",
       " 'such',\n",
       " 'good',\n",
       " 'many',\n",
       " 'respectable',\n",
       " 'unable',\n",
       " 'such',\n",
       " 'special',\n",
       " 'much',\n",
       " 'interested',\n",
       " 'special',\n",
       " 'impossible',\n",
       " 'absolute',\n",
       " 'necessary',\n",
       " 'important',\n",
       " 'aware',\n",
       " 'necessary',\n",
       " 'full',\n",
       " 'improper',\n",
       " 'wise',\n",
       " 'discreet',\n",
       " 'adjourned',\n",
       " 'long',\n",
       " 'great',\n",
       " 'same',\n",
       " 'political',\n",
       " 'high',\n",
       " 'other']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adjectives[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While these are basic methods of extraction, they do serve as building blocks for bigger questions like: what kinds of verbs do different Congressional speakers use? Do the adjectives Congressional speakers use change over time?\n",
    "\n",
    "Or, what adjectives do different politians use to discuss climate change? Here, an absence of adjectives would be telling, too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntactic Units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract a words syntactic dependency (labeled __.dep___)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_and_dep = []\n",
    "\n",
    "for ls in gladstone_doc:\n",
    "    for word in ls:\n",
    "        row = (word.text, word.pos_, word.dep_)\n",
    "        token_and_dep.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 'VERB', 'ROOT'),\n",
       " (',', 'PUNCT', 'punct'),\n",
       " ('the', 'DET', 'det'),\n",
       " ('Reform', 'PROPN', 'compound'),\n",
       " ('Bill', 'PROPN', 'nsubj'),\n",
       " ('had', 'AUX', 'aux'),\n",
       " ('not', 'PART', 'neg'),\n",
       " ('produced', 'VERB', 'ccomp'),\n",
       " ('at', 'ADP', 'prep'),\n",
       " ('Liverpool', 'PROPN', 'pobj'),\n",
       " ('the', 'DET', 'det'),\n",
       " ('effect', 'NOUN', 'dobj'),\n",
       " ('which', 'DET', 'nsubjpass'),\n",
       " ('had', 'AUX', 'aux'),\n",
       " ('been', 'AUX', 'auxpass'),\n",
       " ('anticipated', 'VERB', 'relcl'),\n",
       " ('from', 'ADP', 'prep'),\n",
       " ('it', 'PRON', 'pobj'),\n",
       " ('.', 'PUNCT', 'punct'),\n",
       " ('He', 'PRON', 'nsubj'),\n",
       " ('would', 'VERB', 'aux'),\n",
       " ('venture', 'VERB', 'ROOT'),\n",
       " ('to', 'PART', 'aux'),\n",
       " ('say', 'VERB', 'xcomp'),\n",
       " (',', 'PUNCT', 'punct'),\n",
       " ('however', 'ADV', 'advmod'),\n",
       " (',', 'PUNCT', 'punct'),\n",
       " ('that', 'SCONJ', 'mark'),\n",
       " ('no', 'DET', 'det'),\n",
       " ('corrupt', 'ADJ', 'amod')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_and_dep[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a moment to observe these results. We don't need to be a linguistic to see that __venture__ is labeled ROOT VERB or that __anticipated__ is a verb in a relative clause, or relcl. \n",
    "\n",
    "> For a full list of syntactic tags, see the [English dependency labels in spaCy's documentation](https://spacy.io/api/annotation#dependency-parsing-english)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can focus our results by extracting just subjects, or the nouns performing some sort of action. The following code uses a conditional statement (an \"if\" statement) to determine whether the syntactic dependency tag is __nsubj__ (for noun subject), or __nsubjpass__ for (passive noun subject). If the dependency tag is either of these, the word is cast to a string and appended to subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = []\n",
    "\n",
    "for ls in gladstone_doc:\n",
    "    for word in ls:\n",
    "        if word.dep_ in ('nsubj', 'nsubjpass'):\n",
    "            subjects.append(str(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bill',\n",
       " 'which',\n",
       " 'He',\n",
       " 'influence',\n",
       " 'practices',\n",
       " 'he',\n",
       " 'he',\n",
       " 'petition',\n",
       " 'it',\n",
       " 'persons',\n",
       " 'he',\n",
       " 'person',\n",
       " 'It',\n",
       " 'Governor',\n",
       " 'which',\n",
       " 'It',\n",
       " 'Gentleman',\n",
       " 'Governor',\n",
       " 'appointment',\n",
       " 'conduct',\n",
       " 'Nothing',\n",
       " 'nothing',\n",
       " 'nothing',\n",
       " 'appointment',\n",
       " 'it',\n",
       " 'order',\n",
       " 'allusions',\n",
       " 'he',\n",
       " 'Huskisson',\n",
       " 'sixpence']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjects[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason we decided to cast the words to strings is because then we can perform string operations on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowercase_subjects = [word.lower() for word in subjects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bill',\n",
       " 'which',\n",
       " 'he',\n",
       " 'influence',\n",
       " 'practices',\n",
       " 'he',\n",
       " 'he',\n",
       " 'petition',\n",
       " 'it',\n",
       " 'persons',\n",
       " 'he',\n",
       " 'person',\n",
       " 'it',\n",
       " 'governor',\n",
       " 'which',\n",
       " 'it',\n",
       " 'gentleman',\n",
       " 'governor',\n",
       " 'appointment',\n",
       " 'conduct',\n",
       " 'nothing',\n",
       " 'nothing',\n",
       " 'nothing',\n",
       " 'appointment',\n",
       " 'it',\n",
       " 'order',\n",
       " 'allusions',\n",
       " 'he',\n",
       " 'huskisson',\n",
       " 'sixpence']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lowercase_subjects[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's your turn!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Extracting Parts-of-Speech from the Stanford Congressional Records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will use spaCy on Bob Dole's Congressional speeches. \n",
    "\n",
    "First, import the required modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, csv, pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After importing the modules we want to read in the Stanford Congressional Records. \n",
    "\n",
    "Before we can read in the data, however, we should inspect the way in which the data is stored. Unlike the __gladstone_speeches__ data, which was conveniently aggregated in a .csv file, the Stanford Congressional Records are scattered across several sub-directories and .txt files. To see what I mean, let's look at the file hierarchy for the Stanford Congressional Records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/scratch/group/oit_research_data/stanford_congress/__MACOSX',\n",
       " '/scratch/group/oit_research_data/stanford_congress/speakermap_stats',\n",
       " '/scratch/group/oit_research_data/stanford_congress/keywords.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/topic_phrases.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/congress_download.sh',\n",
       " '/scratch/group/oit_research_data/stanford_congress/vocabulary',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily',\n",
       " '/scratch/group/oit_research_data/stanford_congress/false_matches.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/party_full',\n",
       " '/scratch/group/oit_research_data/stanford_congress/partisan_phrases',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-bound',\n",
       " '/scratch/group/oit_research_data/stanford_congress/audit']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_path_to_congress = \"/scratch/group/oit_research_data/stanford_congress\"\n",
    "\n",
    "glob.glob('{}/*'.format(directory_path_to_congress))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the Stanford Congressional Records includes data from __keywords__ to __partisan_phrases__. \n",
    "\n",
    "We are interested in the __hein-daily__ folder, which contains Congressional speech data. We can view the contents of the __hein-daily__ folder by adding it to our directory path. \n",
    "\n",
    "The following code shows the first 30 files in __hein-daily__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/scratch/group/oit_research_data/stanford_congress/hein-daily/byspeaker_2gram_107.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/byparty_2gram_103.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/speeches_104.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/byparty_2gram_104.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/speeches_103.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/byspeaker_2gram_100.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/107_SpeakerMap.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/byspeaker_2gram_109.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/098_SpeakerMap.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/100_SpeakerMap.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/descr_103.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/descr_104.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/109_SpeakerMap.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/descr_112.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/speeches_112.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/byspeaker_2gram_098.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/byspeaker_2gram_111.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/110_SpeakerMap.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/byparty_2gram_112.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/102_SpeakerMap.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/descr_105.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/descr_102.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/byspeaker_2gram_108.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/105_SpeakerMap.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/speeches_102.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/byparty_2gram_105.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/byspeaker_2gram_101.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/byspeaker_2gram_106.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/speeches_105.txt',\n",
       " '/scratch/group/oit_research_data/stanford_congress/hein-daily/byparty_2gram_102.txt']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_path_to_hein_daily = \"/scratch/group/oit_research_data/stanford_congress/hein-daily\"\n",
    "\n",
    "glob.glob('{}/*'.format(directory_path_to_hein_daily))[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of files in here! And, at first glance many of them seem unrelated. We have files with labels that include: __2_gram__, __SpeakerMap__, __descr___, and __speeches___.\n",
    "\n",
    "We are just interested in .txt files with the prefix __speeches___ and the prefix __descr___. \n",
    "\n",
    "__speeches___ contains the actual speeches recorded in Congress and __descr___ contains associated metadata like the date of the speech and the speaker. \n",
    "\n",
    "The following code iterates through each __speeches___ .txt file and each __descr___ .txt file and combines them into pandas DataFrames that resembles our __gladstone_speeches__ data.\n",
    "\n",
    "Note: this code takes a few minutes to run. While it runs, it prints lines that were ommitted because of formatting or parsing errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = '/scratch/group/oit_research_data/stanford_congress/hein-bound/'\n",
    "file_type = 'txt'\n",
    "delim ='|'\n",
    "\n",
    "speeches_df = pd.concat([pd.read_csv(f, sep=delim, encoding=\"ISO-8859-1\", error_bad_lines=False, quoting=csv.QUOTE_NONE) for f in glob.glob(directory + \"speeches_*\"+file_type)])\n",
    "\n",
    "descr_df = pd.concat([pd.read_csv(f, sep=delim, encoding=\"ISO-8859-1\", error_bad_lines=False, quoting=csv.QUOTE_NONE) for f in glob.glob(directory + \"descr_*\"+file_type)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have two DataFrames, one with speeches and one with metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech_id</th>\n",
       "      <th>speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>740000001</td>\n",
       "      <td>The Chair lays before the Senate the credentia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>740000002</td>\n",
       "      <td>(John C. Crockett) proceeded to read the certi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>740000003</td>\n",
       "      <td>Mr. President. I suggest that credentials foun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>740000004</td>\n",
       "      <td>Is there objection to the request? The Chair h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>740000005</td>\n",
       "      <td>Secretary of State.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382520</th>\n",
       "      <td>940382525</td>\n",
       "      <td>Mr. Speaker. it is a great personal honor for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382521</th>\n",
       "      <td>940382526</td>\n",
       "      <td>Mr. Speaker. given the fact that Chairman MADD...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382522</th>\n",
       "      <td>940382527</td>\n",
       "      <td>Mr. Speaker. taie 94th Congress has officially...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382523</th>\n",
       "      <td>940382528</td>\n",
       "      <td>designateApril 24 as a National Day of Remembr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382524</th>\n",
       "      <td>940382529</td>\n",
       "      <td>Mr. Speaker. I would like to submit for the re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17394641 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        speech_id                                             speech\n",
       "0       740000001  The Chair lays before the Senate the credentia...\n",
       "1       740000002  (John C. Crockett) proceeded to read the certi...\n",
       "2       740000003  Mr. President. I suggest that credentials foun...\n",
       "3       740000004  Is there objection to the request? The Chair h...\n",
       "4       740000005                                Secretary of State.\n",
       "...           ...                                                ...\n",
       "382520  940382525  Mr. Speaker. it is a great personal honor for ...\n",
       "382521  940382526  Mr. Speaker. given the fact that Chairman MADD...\n",
       "382522  940382527  Mr. Speaker. taie 94th Congress has officially...\n",
       "382523  940382528  designateApril 24 as a National Day of Remembr...\n",
       "382524  940382529  Mr. Speaker. I would like to submit for the re...\n",
       "\n",
       "[17394641 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speeches_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech_id</th>\n",
       "      <th>chamber</th>\n",
       "      <th>date</th>\n",
       "      <th>number_within_file</th>\n",
       "      <th>speaker</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>state</th>\n",
       "      <th>gender</th>\n",
       "      <th>line_start</th>\n",
       "      <th>line_end</th>\n",
       "      <th>file</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1110000001</td>\n",
       "      <td>H</td>\n",
       "      <td>20090106</td>\n",
       "      <td>1</td>\n",
       "      <td>The CLERK</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Special</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "      <td>01062009.txt</td>\n",
       "      <td>107</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1110000002</td>\n",
       "      <td>H</td>\n",
       "      <td>20090106</td>\n",
       "      <td>2</td>\n",
       "      <td>The CLERK</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Special</td>\n",
       "      <td>77</td>\n",
       "      <td>100</td>\n",
       "      <td>01062009.txt</td>\n",
       "      <td>836</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1110000003</td>\n",
       "      <td>H</td>\n",
       "      <td>20090106</td>\n",
       "      <td>3</td>\n",
       "      <td>The CLERK</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Special</td>\n",
       "      <td>565</td>\n",
       "      <td>591</td>\n",
       "      <td>01062009.txt</td>\n",
       "      <td>219</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1110000004</td>\n",
       "      <td>H</td>\n",
       "      <td>20090106</td>\n",
       "      <td>4</td>\n",
       "      <td>The CLERK</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Special</td>\n",
       "      <td>593</td>\n",
       "      <td>613</td>\n",
       "      <td>01062009.txt</td>\n",
       "      <td>596</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1110000005</td>\n",
       "      <td>H</td>\n",
       "      <td>20090106</td>\n",
       "      <td>5</td>\n",
       "      <td>The CLERK</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Special</td>\n",
       "      <td>616</td>\n",
       "      <td>622</td>\n",
       "      <td>01062009.txt</td>\n",
       "      <td>200</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261804</th>\n",
       "      <td>780261805</td>\n",
       "      <td>H</td>\n",
       "      <td>19441219</td>\n",
       "      <td>1345</td>\n",
       "      <td>The SPEAKER pro tempore</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Special</td>\n",
       "      <td>35449</td>\n",
       "      <td>35451</td>\n",
       "      <td>12191944.txt</td>\n",
       "      <td>64</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261805</th>\n",
       "      <td>780261806</td>\n",
       "      <td>H</td>\n",
       "      <td>19441219</td>\n",
       "      <td>1346</td>\n",
       "      <td>Mr. RAMSPECK</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>RAMSPECK</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>35489</td>\n",
       "      <td>35492</td>\n",
       "      <td>12191944.txt</td>\n",
       "      <td>102</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261806</th>\n",
       "      <td>780261807</td>\n",
       "      <td>H</td>\n",
       "      <td>19441219</td>\n",
       "      <td>1347</td>\n",
       "      <td>The SPEAKER pro tempore</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Special</td>\n",
       "      <td>35494</td>\n",
       "      <td>35501</td>\n",
       "      <td>12191944.txt</td>\n",
       "      <td>246</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261807</th>\n",
       "      <td>780261808</td>\n",
       "      <td>H</td>\n",
       "      <td>19441219</td>\n",
       "      <td>1348</td>\n",
       "      <td>Mr. ANDERSON of New York</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>ANDERSON</td>\n",
       "      <td>New York</td>\n",
       "      <td>M</td>\n",
       "      <td>35520</td>\n",
       "      <td>35540</td>\n",
       "      <td>12191944.txt</td>\n",
       "      <td>751</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261808</th>\n",
       "      <td>780261809</td>\n",
       "      <td>H</td>\n",
       "      <td>19441219</td>\n",
       "      <td>1349</td>\n",
       "      <td>Mr. LEA of California</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>LEA</td>\n",
       "      <td>California</td>\n",
       "      <td>M</td>\n",
       "      <td>35541</td>\n",
       "      <td>35549</td>\n",
       "      <td>12191944.txt</td>\n",
       "      <td>328</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17395884 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         speech_id chamber      date  number_within_file  \\\n",
       "0       1110000001       H  20090106                   1   \n",
       "1       1110000002       H  20090106                   2   \n",
       "2       1110000003       H  20090106                   3   \n",
       "3       1110000004       H  20090106                   4   \n",
       "4       1110000005       H  20090106                   5   \n",
       "...            ...     ...       ...                 ...   \n",
       "261804   780261805       H  19441219                1345   \n",
       "261805   780261806       H  19441219                1346   \n",
       "261806   780261807       H  19441219                1347   \n",
       "261807   780261808       H  19441219                1348   \n",
       "261808   780261809       H  19441219                1349   \n",
       "\n",
       "                         speaker first_name last_name       state   gender  \\\n",
       "0                      The CLERK    Unknown   Unknown     Unknown  Special   \n",
       "1                      The CLERK    Unknown   Unknown     Unknown  Special   \n",
       "2                      The CLERK    Unknown   Unknown     Unknown  Special   \n",
       "3                      The CLERK    Unknown   Unknown     Unknown  Special   \n",
       "4                      The CLERK    Unknown   Unknown     Unknown  Special   \n",
       "...                          ...        ...       ...         ...      ...   \n",
       "261804   The SPEAKER pro tempore    Unknown   Unknown     Unknown  Special   \n",
       "261805              Mr. RAMSPECK    Unknown  RAMSPECK     Unknown        M   \n",
       "261806   The SPEAKER pro tempore    Unknown   Unknown     Unknown  Special   \n",
       "261807  Mr. ANDERSON of New York    Unknown  ANDERSON    New York        M   \n",
       "261808     Mr. LEA of California    Unknown       LEA  California        M   \n",
       "\n",
       "        line_start  line_end          file  char_count  word_count  \n",
       "0               66        70  01062009.txt         107          16  \n",
       "1               77       100  01062009.txt         836         134  \n",
       "2              565       591  01062009.txt         219          37  \n",
       "3              593       613  01062009.txt         596          92  \n",
       "4              616       622  01062009.txt         200          34  \n",
       "...            ...       ...           ...         ...         ...  \n",
       "261804       35449     35451  12191944.txt          64          11  \n",
       "261805       35489     35492  12191944.txt         102          17  \n",
       "261806       35494     35501  12191944.txt         246          37  \n",
       "261807       35520     35540  12191944.txt         751         118  \n",
       "261808       35541     35549  12191944.txt         328          46  \n",
       "\n",
       "[17395884 rows x 14 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of analysis, let's merge these into a single DataFrame where the speakers in the speaker column relate to the text in the speech column, and so forth.\n",
    "\n",
    "The following code merges the two DataFrames by the `speech_id` column (a unique identifier) and also replaces any null values (NAs) with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.merge(speeches_df, descr_df, on='speech_id').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech_id</th>\n",
       "      <th>speech</th>\n",
       "      <th>chamber</th>\n",
       "      <th>date</th>\n",
       "      <th>number_within_file</th>\n",
       "      <th>speaker</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>state</th>\n",
       "      <th>gender</th>\n",
       "      <th>line_start</th>\n",
       "      <th>line_end</th>\n",
       "      <th>file</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>740000001</td>\n",
       "      <td>The Chair lays before the Senate the credentia...</td>\n",
       "      <td>S</td>\n",
       "      <td>19350103</td>\n",
       "      <td>1</td>\n",
       "      <td>The VICE PRESIDENT</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Special</td>\n",
       "      <td>48</td>\n",
       "      <td>51</td>\n",
       "      <td>01031935.txt</td>\n",
       "      <td>184</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>740000002</td>\n",
       "      <td>(John C. Crockett) proceeded to read the certi...</td>\n",
       "      <td>S</td>\n",
       "      <td>19350103</td>\n",
       "      <td>2</td>\n",
       "      <td>The Chief Clerk</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Special</td>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "      <td>01031935.txt</td>\n",
       "      <td>124</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>740000003</td>\n",
       "      <td>Mr. President. I suggest that credentials foun...</td>\n",
       "      <td>S</td>\n",
       "      <td>19350103</td>\n",
       "      <td>3</td>\n",
       "      <td>Mr. ROBINSON</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>ROBINSON</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>55</td>\n",
       "      <td>57</td>\n",
       "      <td>01031935.txt</td>\n",
       "      <td>153</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>740000004</td>\n",
       "      <td>Is there objection to the request? The Chair h...</td>\n",
       "      <td>S</td>\n",
       "      <td>19350103</td>\n",
       "      <td>4</td>\n",
       "      <td>The VICE PRESIDENT</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Special</td>\n",
       "      <td>58</td>\n",
       "      <td>62</td>\n",
       "      <td>01031935.txt</td>\n",
       "      <td>238</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>740000005</td>\n",
       "      <td>Secretary of State.</td>\n",
       "      <td>S</td>\n",
       "      <td>19350103</td>\n",
       "      <td>5</td>\n",
       "      <td>Mrs. MARGUERITE P. BACA</td>\n",
       "      <td>MARGUERITE P.</td>\n",
       "      <td>BACA</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>F</td>\n",
       "      <td>273</td>\n",
       "      <td>275</td>\n",
       "      <td>01031935.txt</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17394636</th>\n",
       "      <td>940382525</td>\n",
       "      <td>Mr. Speaker. it is a great personal honor for ...</td>\n",
       "      <td>E</td>\n",
       "      <td>19761001</td>\n",
       "      <td>4819</td>\n",
       "      <td>Mr. BIAGGI</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>BIAGGI</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>383002</td>\n",
       "      <td>383082</td>\n",
       "      <td>10011976.txt</td>\n",
       "      <td>2782</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17394637</th>\n",
       "      <td>940382526</td>\n",
       "      <td>Mr. Speaker. given the fact that Chairman MADD...</td>\n",
       "      <td>E</td>\n",
       "      <td>19761001</td>\n",
       "      <td>4820</td>\n",
       "      <td>Mr. PHILLIP BURTON</td>\n",
       "      <td>PHILLIP</td>\n",
       "      <td>BURTON</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>383088</td>\n",
       "      <td>383104</td>\n",
       "      <td>10011976.txt</td>\n",
       "      <td>337</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17394638</th>\n",
       "      <td>940382527</td>\n",
       "      <td>Mr. Speaker. taie 94th Congress has officially...</td>\n",
       "      <td>E</td>\n",
       "      <td>19761001</td>\n",
       "      <td>4821</td>\n",
       "      <td>Mr. JOHNSON of California</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>JOHNSON</td>\n",
       "      <td>California</td>\n",
       "      <td>M</td>\n",
       "      <td>383111</td>\n",
       "      <td>383127</td>\n",
       "      <td>10011976.txt</td>\n",
       "      <td>586</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17394639</th>\n",
       "      <td>940382528</td>\n",
       "      <td>designateApril 24 as a National Day of Remembr...</td>\n",
       "      <td>E</td>\n",
       "      <td>19761001</td>\n",
       "      <td>4822</td>\n",
       "      <td>For.-......To</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>......TO</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>383248</td>\n",
       "      <td>383342</td>\n",
       "      <td>10011976.txt</td>\n",
       "      <td>6066</td>\n",
       "      <td>892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17394640</th>\n",
       "      <td>940382529</td>\n",
       "      <td>Mr. Speaker. I would like to submit for the re...</td>\n",
       "      <td>E</td>\n",
       "      <td>19761001</td>\n",
       "      <td>4823</td>\n",
       "      <td>Mr. BLOUIN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>BLOUIN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>384507</td>\n",
       "      <td>384543</td>\n",
       "      <td>10011976.txt</td>\n",
       "      <td>1340</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17394641 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          speech_id                                             speech  \\\n",
       "0         740000001  The Chair lays before the Senate the credentia...   \n",
       "1         740000002  (John C. Crockett) proceeded to read the certi...   \n",
       "2         740000003  Mr. President. I suggest that credentials foun...   \n",
       "3         740000004  Is there objection to the request? The Chair h...   \n",
       "4         740000005                                Secretary of State.   \n",
       "...             ...                                                ...   \n",
       "17394636  940382525  Mr. Speaker. it is a great personal honor for ...   \n",
       "17394637  940382526  Mr. Speaker. given the fact that Chairman MADD...   \n",
       "17394638  940382527  Mr. Speaker. taie 94th Congress has officially...   \n",
       "17394639  940382528  designateApril 24 as a National Day of Remembr...   \n",
       "17394640  940382529  Mr. Speaker. I would like to submit for the re...   \n",
       "\n",
       "         chamber      date  number_within_file                    speaker  \\\n",
       "0              S  19350103                   1         The VICE PRESIDENT   \n",
       "1              S  19350103                   2            The Chief Clerk   \n",
       "2              S  19350103                   3               Mr. ROBINSON   \n",
       "3              S  19350103                   4         The VICE PRESIDENT   \n",
       "4              S  19350103                   5    Mrs. MARGUERITE P. BACA   \n",
       "...          ...       ...                 ...                        ...   \n",
       "17394636       E  19761001                4819                 Mr. BIAGGI   \n",
       "17394637       E  19761001                4820         Mr. PHILLIP BURTON   \n",
       "17394638       E  19761001                4821  Mr. JOHNSON of California   \n",
       "17394639       E  19761001                4822              For.-......To   \n",
       "17394640       E  19761001                4823                 Mr. BLOUIN   \n",
       "\n",
       "             first_name last_name       state   gender  line_start  line_end  \\\n",
       "0               Unknown   Unknown     Unknown  Special          48        51   \n",
       "1               Unknown   Unknown     Unknown  Special          52        54   \n",
       "2               Unknown  ROBINSON     Unknown        M          55        57   \n",
       "3               Unknown   Unknown     Unknown  Special          58        62   \n",
       "4         MARGUERITE P.      BACA     Unknown        F         273       275   \n",
       "...                 ...       ...         ...      ...         ...       ...   \n",
       "17394636        Unknown    BIAGGI     Unknown        M      383002    383082   \n",
       "17394637        PHILLIP    BURTON     Unknown        M      383088    383104   \n",
       "17394638        Unknown   JOHNSON  California        M      383111    383127   \n",
       "17394639        Unknown  ......TO     Unknown        M      383248    383342   \n",
       "17394640        Unknown    BLOUIN     Unknown        M      384507    384543   \n",
       "\n",
       "                  file  char_count  word_count  \n",
       "0         01031935.txt         184          32  \n",
       "1         01031935.txt         124          21  \n",
       "2         01031935.txt         153          30  \n",
       "3         01031935.txt         238          44  \n",
       "4         01031935.txt          19           3  \n",
       "...                ...         ...         ...  \n",
       "17394636  10011976.txt        2782         453  \n",
       "17394637  10011976.txt         337          60  \n",
       "17394638  10011976.txt         586         102  \n",
       "17394639  10011976.txt        6066         892  \n",
       "17394640  10011976.txt        1340         225  \n",
       "\n",
       "[17394641 rows x 15 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`all_data` is a large DataFrame. To make analysis more accessible, let's take a subset of the data.\n",
    "\n",
    "A subset is a portion of the data made up of criteria of our choosing. The following code takes a subset of just speeches by Mr. Dole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob_dole = all_data[(all_data.speaker == \"Mr. DOLE\")].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech_id</th>\n",
       "      <th>speech</th>\n",
       "      <th>chamber</th>\n",
       "      <th>date</th>\n",
       "      <th>number_within_file</th>\n",
       "      <th>speaker</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>state</th>\n",
       "      <th>gender</th>\n",
       "      <th>line_start</th>\n",
       "      <th>line_end</th>\n",
       "      <th>file</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>617680</th>\n",
       "      <td>970000180</td>\n",
       "      <td>Mr. President. despite all the debate over tax...</td>\n",
       "      <td>S</td>\n",
       "      <td>19810105</td>\n",
       "      <td>180</td>\n",
       "      <td>Mr. DOLE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>DOLE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>3410</td>\n",
       "      <td>3425</td>\n",
       "      <td>01051981.txt</td>\n",
       "      <td>602</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617687</th>\n",
       "      <td>970000187</td>\n",
       "      <td>Mr. President. I send to the desk a bill to cl...</td>\n",
       "      <td>S</td>\n",
       "      <td>19810105</td>\n",
       "      <td>187</td>\n",
       "      <td>Mr. DOLE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>DOLE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>6423</td>\n",
       "      <td>6427</td>\n",
       "      <td>01051981.txt</td>\n",
       "      <td>147</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617689</th>\n",
       "      <td>970000189</td>\n",
       "      <td>Mr. President. today I am introducing legislat...</td>\n",
       "      <td>S</td>\n",
       "      <td>19810105</td>\n",
       "      <td>189</td>\n",
       "      <td>Mr. DOLE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>DOLE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>6880</td>\n",
       "      <td>6890</td>\n",
       "      <td>01051981.txt</td>\n",
       "      <td>409</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617690</th>\n",
       "      <td>970000190</td>\n",
       "      <td>Mr. President. one of the most pressing and se...</td>\n",
       "      <td>S</td>\n",
       "      <td>19810105</td>\n",
       "      <td>190</td>\n",
       "      <td>Mr. DOLE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>DOLE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>7015</td>\n",
       "      <td>7022</td>\n",
       "      <td>01051981.txt</td>\n",
       "      <td>297</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617692</th>\n",
       "      <td>970000192</td>\n",
       "      <td>Mr. President. the Senator from Kansas today w...</td>\n",
       "      <td>S</td>\n",
       "      <td>19810105</td>\n",
       "      <td>192</td>\n",
       "      <td>Mr. DOLE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>DOLE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>7582</td>\n",
       "      <td>7662</td>\n",
       "      <td>01051981.txt</td>\n",
       "      <td>2657</td>\n",
       "      <td>438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17392087</th>\n",
       "      <td>940379976</td>\n",
       "      <td>Mr. President. I rise to pay tribute to the re...</td>\n",
       "      <td>S</td>\n",
       "      <td>19761001</td>\n",
       "      <td>2270</td>\n",
       "      <td>Mr. DOLE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>DOLE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>161175</td>\n",
       "      <td>161210</td>\n",
       "      <td>10011976.txt</td>\n",
       "      <td>1285</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17392088</th>\n",
       "      <td>940379977</td>\n",
       "      <td>Mr. President. I am particularly appreciative ...</td>\n",
       "      <td>S</td>\n",
       "      <td>19761001</td>\n",
       "      <td>2271</td>\n",
       "      <td>Mr. DOLE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>DOLE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>161212</td>\n",
       "      <td>161247</td>\n",
       "      <td>10011976.txt</td>\n",
       "      <td>1294</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17392089</th>\n",
       "      <td>940379978</td>\n",
       "      <td>Mr. President. HIRAM FONG comes from what is g...</td>\n",
       "      <td>S</td>\n",
       "      <td>19761001</td>\n",
       "      <td>2272</td>\n",
       "      <td>Mr. DOLE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>DOLE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>161249</td>\n",
       "      <td>161280</td>\n",
       "      <td>10011976.txt</td>\n",
       "      <td>1161</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17392090</th>\n",
       "      <td>940379979</td>\n",
       "      <td>Mr. President. the retirement of Senator JOHN ...</td>\n",
       "      <td>S</td>\n",
       "      <td>19761001</td>\n",
       "      <td>2273</td>\n",
       "      <td>Mr. DOLE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>DOLE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>161282</td>\n",
       "      <td>161319</td>\n",
       "      <td>10011976.txt</td>\n",
       "      <td>1403</td>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17392091</th>\n",
       "      <td>940379980</td>\n",
       "      <td>Mr. President. the adjournment of this session...</td>\n",
       "      <td>S</td>\n",
       "      <td>19761001</td>\n",
       "      <td>2274</td>\n",
       "      <td>Mr. DOLE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>DOLE</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>M</td>\n",
       "      <td>161321</td>\n",
       "      <td>161394</td>\n",
       "      <td>10011976.txt</td>\n",
       "      <td>2297</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49119 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          speech_id                                             speech  \\\n",
       "617680    970000180  Mr. President. despite all the debate over tax...   \n",
       "617687    970000187  Mr. President. I send to the desk a bill to cl...   \n",
       "617689    970000189  Mr. President. today I am introducing legislat...   \n",
       "617690    970000190  Mr. President. one of the most pressing and se...   \n",
       "617692    970000192  Mr. President. the Senator from Kansas today w...   \n",
       "...             ...                                                ...   \n",
       "17392087  940379976  Mr. President. I rise to pay tribute to the re...   \n",
       "17392088  940379977  Mr. President. I am particularly appreciative ...   \n",
       "17392089  940379978  Mr. President. HIRAM FONG comes from what is g...   \n",
       "17392090  940379979  Mr. President. the retirement of Senator JOHN ...   \n",
       "17392091  940379980  Mr. President. the adjournment of this session...   \n",
       "\n",
       "         chamber      date  number_within_file   speaker first_name last_name  \\\n",
       "617680         S  19810105                 180  Mr. DOLE    Unknown      DOLE   \n",
       "617687         S  19810105                 187  Mr. DOLE    Unknown      DOLE   \n",
       "617689         S  19810105                 189  Mr. DOLE    Unknown      DOLE   \n",
       "617690         S  19810105                 190  Mr. DOLE    Unknown      DOLE   \n",
       "617692         S  19810105                 192  Mr. DOLE    Unknown      DOLE   \n",
       "...          ...       ...                 ...       ...        ...       ...   \n",
       "17392087       S  19761001                2270  Mr. DOLE    Unknown      DOLE   \n",
       "17392088       S  19761001                2271  Mr. DOLE    Unknown      DOLE   \n",
       "17392089       S  19761001                2272  Mr. DOLE    Unknown      DOLE   \n",
       "17392090       S  19761001                2273  Mr. DOLE    Unknown      DOLE   \n",
       "17392091       S  19761001                2274  Mr. DOLE    Unknown      DOLE   \n",
       "\n",
       "            state gender  line_start  line_end          file  char_count  \\\n",
       "617680    Unknown      M        3410      3425  01051981.txt         602   \n",
       "617687    Unknown      M        6423      6427  01051981.txt         147   \n",
       "617689    Unknown      M        6880      6890  01051981.txt         409   \n",
       "617690    Unknown      M        7015      7022  01051981.txt         297   \n",
       "617692    Unknown      M        7582      7662  01051981.txt        2657   \n",
       "...           ...    ...         ...       ...           ...         ...   \n",
       "17392087  Unknown      M      161175    161210  10011976.txt        1285   \n",
       "17392088  Unknown      M      161212    161247  10011976.txt        1294   \n",
       "17392089  Unknown      M      161249    161280  10011976.txt        1161   \n",
       "17392090  Unknown      M      161282    161319  10011976.txt        1403   \n",
       "17392091  Unknown      M      161321    161394  10011976.txt        2297   \n",
       "\n",
       "          word_count  \n",
       "617680           107  \n",
       "617687            25  \n",
       "617689            60  \n",
       "617690            47  \n",
       "617692           438  \n",
       "...              ...  \n",
       "17392087         222  \n",
       "17392088         217  \n",
       "17392089         180  \n",
       "17392090         229  \n",
       "17392091         377  \n",
       "\n",
       "[49119 rows x 15 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob_dole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some of the obvious differences between `bob_dole` and `all_data`. For one, `all_data` consists of 17,394,641 rows whereas `bob_dole` has 49,119. This difference in size will make working with `bob_dole` much easier! \n",
    "\n",
    "But, let's make processing the `bob_dole` even data easier for spaCy. The following code creates a pandas series from just Dole's speeches. A series is lighter weight than a formatted DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob_dole_set = bob_dole['speech'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "617680      Mr. President. despite all the debate over tax...\n",
       "617687      Mr. President. I send to the desk a bill to cl...\n",
       "617689      Mr. President. today I am introducing legislat...\n",
       "617690      Mr. President. one of the most pressing and se...\n",
       "617692      Mr. President. the Senator from Kansas today w...\n",
       "                                  ...                        \n",
       "17392087    Mr. President. I rise to pay tribute to the re...\n",
       "17392088    Mr. President. I am particularly appreciative ...\n",
       "17392089    Mr. President. HIRAM FONG comes from what is g...\n",
       "17392090    Mr. President. the retirement of Senator JOHN ...\n",
       "17392091    Mr. President. the adjournment of this session...\n",
       "Name: speech, Length: 49119, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob_dole_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number on the left is an index, a unique numerical representation of a sentence's location, and the text on the right are Dole's speeches.\n",
    "\n",
    "We can now run `nlp.pipe()` on the data. `bob_dole` is a larger variable than `gladstone_speeches`, so it will take longer to run.\n",
    "\n",
    "Earlier we glossed over the `%%time` magic command. \n",
    "\n",
    "Our `%%time` magic command tells us how long a cell took to complete. The output of `%%time` consists of: user time, system time, and total time. System time is the amount of time the compuer used to calculate results. User time refers to the amount of time we spent waiting to compute. If lots of other processes are running on M2 we might have to wait longer to process our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 21s, sys: 2min, total: 11min 21s\n",
      "Wall time: 11min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "bob_dole_doc = list(nlp.pipe(bob_dole_set, disable = [\"ent\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's your turn to take away the rest!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Bob Dole's speeches:\n",
    " - extract words and their lemmatized forms\n",
    " - extract words and their parts-of-speech\n",
    " - extract nouns\n",
    " - extract adjectives\n",
    " - extract verbs (our examples only extracted adjectives and nouns, but can you extract verbs?)\n",
    " - extract subjects\n",
    " - extract objects (this will require following the link to the spaCy documentation and seeing for yourself how objects are tagged--hint: you need to find the tags for direct, indirect, and passive objects)\n",
    "\n",
    "After extracting these different parts-of-speech and syntactic units, choose three of these variables and: \n",
    " - count the number of unique occurances\n",
    " - visualize your count (remember to remove stop words where necessary)\n",
    " \n",
    "Make a few observations about your visualizations:\n",
    " - note three things you notice (this can be as simple as \"Dole often uses the verb X\")\n",
    " - note three ways you could build a more sophisticated analyis from your results (for example, \"I could read the debates and contextualize Dole's use of the word X\")\n",
    "\n",
    "\n",
    "<font color=blue>For this assingment to be considered complete you should turn in your Notebook with a) each of the extracted parts-of-speech and syntactic units (show them with __variable_name[:30]__, b) your three visulizations, and c) your observations.</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
